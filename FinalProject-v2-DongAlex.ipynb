{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f487b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d175f0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdmolops import GetAdjacencyMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b0dc94a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0a10495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cefd2777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import NNConv, global_add_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741b36de",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e798b561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>name</th>\n",
       "      <th>p_np</th>\n",
       "      <th>smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Propanolol</td>\n",
       "      <td>1</td>\n",
       "      <td>[Cl].CC(C)NCC(O)COc1cccc2ccccc12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Terbutylchlorambucil</td>\n",
       "      <td>1</td>\n",
       "      <td>C(=O)(OC(C)(C)C)CCCc1ccc(cc1)N(CCCl)CCCl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>40730</td>\n",
       "      <td>1</td>\n",
       "      <td>c12c3c(N4CCN(C)CC4)c(F)cc1c(c(C(O)=O)cn2C(C)CO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>C1CCN(CC1)Cc1cccc(c1)OCCCNC(=O)C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>cloxacillin</td>\n",
       "      <td>1</td>\n",
       "      <td>Cc1onc(c2ccccc2Cl)c1C(=O)N[C@H]3[C@H]4SC(C)(C)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num                  name  p_np  \\\n",
       "0    1            Propanolol     1   \n",
       "1    2  Terbutylchlorambucil     1   \n",
       "2    3                 40730     1   \n",
       "3    4                    24     1   \n",
       "4    5           cloxacillin     1   \n",
       "\n",
       "                                              smiles  \n",
       "0                   [Cl].CC(C)NCC(O)COc1cccc2ccccc12  \n",
       "1           C(=O)(OC(C)(C)C)CCCc1ccc(cc1)N(CCCl)CCCl  \n",
       "2  c12c3c(N4CCN(C)CC4)c(F)cc1c(c(C(O)=O)cn2C(C)CO...  \n",
       "3                   C1CCN(CC1)Cc1cccc(c1)OCCCNC(=O)C  \n",
       "4  Cc1onc(c2ccccc2Cl)c1C(=O)N[C@H]3[C@H]4SC(C)(C)...  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbbp = pd.read_csv(\"BBBP.csv\")\n",
    "bbbp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "36e46d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2050 entries, 0 to 2049\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   num     2050 non-null   int64 \n",
      " 1   name    2050 non-null   object\n",
      " 2   p_np    2050 non-null   int64 \n",
      " 3   smiles  2050 non-null   object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 64.2+ KB\n"
     ]
    }
   ],
   "source": [
    "bbbp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aabc2ec",
   "metadata": {},
   "source": [
    "The data looks good. 2050 entries for each column and there do not seem to be any missing or unusual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "07571252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1567\n",
       "0     483\n",
       "Name: p_np, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbbp['p_np'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264cd12a",
   "metadata": {},
   "source": [
    "Looking at class sizes, we can tell this dataset is very biased. This could be an indication to try stratified sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90429b9",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d6fb81",
   "metadata": {},
   "source": [
    "#### Generate canonical SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "53324919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress warnings from invalid molecules for readability\n",
    "# invalid molecules will be removed\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ca85c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate canon SMILES\n",
    "def gen_canon_smiles(smiles_list):\n",
    "    \n",
    "    invalid_ids = []\n",
    "    canon_smiles = []\n",
    "\n",
    "    for i in range(len(smiles_list)):   \n",
    "        mol = Chem.MolFromSmiles(smiles_list[i])\n",
    "        \n",
    "        # do not append NoneType if invalid\n",
    "        if mol is None: \n",
    "            invalid_ids.append(i)\n",
    "            continue\n",
    "\n",
    "        canon_smiles.append(Chem.MolToSmiles(mol))\n",
    "\n",
    "    return canon_smiles, invalid_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1f43183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate canon smiles\n",
    "canon_smiles, invalid_ids = gen_canon_smiles(bbbp.smiles)\n",
    "\n",
    "# drop rows with invalid SMILES\n",
    "bbbp = bbbp.drop(invalid_ids)\n",
    "\n",
    "# replace SMILES with canon SMILES\n",
    "bbbp.smiles = canon_smiles\n",
    "\n",
    "# drop duplicates to prevent train/valid/test contamination\n",
    "bbbp.drop_duplicates(subset=['smiles'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "96177232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1975 entries, 0 to 2049\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   num     1975 non-null   int64 \n",
      " 1   name    1975 non-null   object\n",
      " 2   p_np    1975 non-null   int64 \n",
      " 3   smiles  1975 non-null   object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 77.1+ KB\n"
     ]
    }
   ],
   "source": [
    "bbbp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc468268",
   "metadata": {},
   "source": [
    "The dataset has been reduced, however, now it should only contain non-duplicate and valid molecules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "63731c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1501\n",
       "0     474\n",
       "Name: p_np, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbbp['p_np'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf418a4",
   "metadata": {},
   "source": [
    "The dataset is still biased."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e201bd16",
   "metadata": {},
   "source": [
    "#### Generate molecular graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "380d1c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(x, permitted_list):\n",
    "    \"\"\"\n",
    "    Maps input elements x which are not in the permitted list to the last element\n",
    "    of the permitted list.\n",
    "    \"\"\"\n",
    "\n",
    "    if x not in permitted_list:\n",
    "        x = permitted_list[-1]\n",
    "\n",
    "    binary_encoding = [int(boolean_value) for boolean_value in list(map(lambda s: x == s, permitted_list))]\n",
    "\n",
    "    return binary_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b38d1b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_atom_features(atom, use_chirality = True, hydrogens_implicit = True):\n",
    "    \"\"\"\n",
    "    Takes an RDKit atom object as input and gives a 1d-numpy array of atom features as output.\n",
    "    \"\"\"\n",
    "\n",
    "    # define list of permitted atoms\n",
    "    \n",
    "    permitted_list_of_atoms =  ['C','N','O','S','F','Si','P','Cl','Br','Mg','Na','Ca','Fe','As','Al','I', 'B','V','K','Tl','Yb','Sb','Sn','Ag','Pd','Co','Se','Ti','Zn', 'Li','Ge','Cu','Au','Ni','Cd','In','Mn','Zr','Cr','Pt','Hg','Pb','Unknown']\n",
    "    \n",
    "    if hydrogens_implicit == False:\n",
    "        permitted_list_of_atoms = ['H'] + permitted_list_of_atoms\n",
    "    \n",
    "    # compute atom features\n",
    "    \n",
    "    atom_type_enc = one_hot_encoding(str(atom.GetSymbol()), permitted_list_of_atoms)\n",
    "    \n",
    "    n_heavy_neighbors_enc = one_hot_encoding(int(atom.GetDegree()), [0, 1, 2, 3, 4, \"MoreThanFour\"])\n",
    "    \n",
    "    formal_charge_enc = one_hot_encoding(int(atom.GetFormalCharge()), [-3, -2, -1, 0, 1, 2, 3, \"Extreme\"])\n",
    "    \n",
    "    hybridisation_type_enc = one_hot_encoding(str(atom.GetHybridization()), [\"S\", \"SP\", \"SP2\", \"SP3\", \"SP3D\", \"SP3D2\", \"OTHER\"])\n",
    "    \n",
    "    is_in_a_ring_enc = [int(atom.IsInRing())]\n",
    "    \n",
    "    is_aromatic_enc = [int(atom.GetIsAromatic())]\n",
    "    \n",
    "    atomic_mass_scaled = [float((atom.GetMass() - 10.812)/116.092)]\n",
    "    \n",
    "    vdw_radius_scaled = [float((Chem.GetPeriodicTable().GetRvdw(atom.GetAtomicNum()) - 1.5)/0.6)]\n",
    "    \n",
    "    covalent_radius_scaled = [float((Chem.GetPeriodicTable().GetRcovalent(atom.GetAtomicNum()) - 0.64)/0.76)]\n",
    "\n",
    "    atom_feature_vector = atom_type_enc + n_heavy_neighbors_enc + formal_charge_enc + hybridisation_type_enc + is_in_a_ring_enc + is_aromatic_enc + atomic_mass_scaled + vdw_radius_scaled + covalent_radius_scaled\n",
    "                                    \n",
    "    if use_chirality == True:\n",
    "        chirality_type_enc = one_hot_encoding(str(atom.GetChiralTag()), [\"CHI_UNSPECIFIED\", \"CHI_TETRAHEDRAL_CW\", \"CHI_TETRAHEDRAL_CCW\", \"CHI_OTHER\"])\n",
    "        atom_feature_vector += chirality_type_enc\n",
    "    \n",
    "    if hydrogens_implicit == True:\n",
    "        n_hydrogens_enc = one_hot_encoding(int(atom.GetTotalNumHs()), [0, 1, 2, 3, 4, \"MoreThanFour\"])\n",
    "        atom_feature_vector += n_hydrogens_enc\n",
    "\n",
    "    return np.array(atom_feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dc69475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bond_features(bond, use_stereochemistry = True):\n",
    "    \"\"\"\n",
    "    Takes an RDKit bond object as input and gives a 1d-numpy array of bond features as output.\n",
    "    \"\"\"\n",
    "\n",
    "    permitted_list_of_bond_types = [Chem.rdchem.BondType.SINGLE, Chem.rdchem.BondType.DOUBLE, Chem.rdchem.BondType.TRIPLE, Chem.rdchem.BondType.AROMATIC]\n",
    "\n",
    "    bond_type_enc = one_hot_encoding(bond.GetBondType(), permitted_list_of_bond_types)\n",
    "    \n",
    "    bond_is_conj_enc = [int(bond.GetIsConjugated())]\n",
    "    \n",
    "    bond_is_in_ring_enc = [int(bond.IsInRing())]\n",
    "    \n",
    "    bond_feature_vector = bond_type_enc + bond_is_conj_enc + bond_is_in_ring_enc\n",
    "    \n",
    "    if use_stereochemistry == True:\n",
    "        stereo_type_enc = one_hot_encoding(str(bond.GetStereo()), [\"STEREOZ\", \"STEREOE\", \"STEREOANY\", \"STEREONONE\"])\n",
    "        bond_feature_vector += stereo_type_enc\n",
    "\n",
    "    return np.array(bond_feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dcb0be32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pytorch_geometric_graph_data_list_from_smiles_and_labels(x_smiles, y):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    x_smiles = [smiles_1, smiles_2, ....] ... a list of SMILES strings\n",
    "    y = [y_1, y_2, ...] ... a list of numerial labels for the SMILES strings (such as associated pKi values)\n",
    "    \n",
    "    Outputs:\n",
    "    data_list = [G_1, G_2, ...] ... a list of torch_geometric.data.Data objects which represent labeled molecular graphs that can readily be used for machine learning\n",
    "    \"\"\"\n",
    "    \n",
    "    data_list = []\n",
    "    \n",
    "    for (smiles, y_val) in zip(x_smiles, y):\n",
    "        \n",
    "        # convert SMILES to RDKit mol object\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "        # get feature dimensions\n",
    "        n_nodes = mol.GetNumAtoms()\n",
    "        n_edges = 2*mol.GetNumBonds()\n",
    "        unrelated_smiles = \"O=O\"\n",
    "        unrelated_mol = Chem.MolFromSmiles(unrelated_smiles)\n",
    "        n_node_features = len(get_atom_features(unrelated_mol.GetAtomWithIdx(0)))\n",
    "        n_edge_features = len(get_bond_features(unrelated_mol.GetBondBetweenAtoms(0,1)))\n",
    "\n",
    "        # construct node feature matrix X of shape (n_nodes, n_node_features)\n",
    "        X = np.zeros((n_nodes, n_node_features))\n",
    "\n",
    "        for atom in mol.GetAtoms():\n",
    "            X[atom.GetIdx(), :] = get_atom_features(atom)\n",
    "            \n",
    "        X = torch.tensor(X, dtype = torch.float)\n",
    "        \n",
    "        # construct edge index array E of shape (2, n_edges)\n",
    "        (rows, cols) = np.nonzero(GetAdjacencyMatrix(mol))\n",
    "        torch_rows = torch.from_numpy(rows.astype(np.int64)).to(torch.long)\n",
    "        torch_cols = torch.from_numpy(cols.astype(np.int64)).to(torch.long)\n",
    "        E = torch.stack([torch_rows, torch_cols], dim = 0)\n",
    "        \n",
    "        # construct edge feature array EF of shape (n_edges, n_edge_features)\n",
    "        EF = np.zeros((n_edges, n_edge_features))\n",
    "        \n",
    "        for (k, (i,j)) in enumerate(zip(rows, cols)):\n",
    "            \n",
    "            EF[k] = get_bond_features(mol.GetBondBetweenAtoms(int(i),int(j)))\n",
    "        \n",
    "        EF = torch.tensor(EF, dtype = torch.float)\n",
    "        \n",
    "        # construct label tensor\n",
    "        y_tensor = torch.tensor(np.array([y_val]), dtype = torch.float)\n",
    "        \n",
    "        # construct Pytorch Geometric data object and append to data list\n",
    "        data_list.append(Data(x = X, edge_index = E, edge_attr = EF, y = y_tensor))\n",
    "\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e2a625e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of molecular graph objects from list of SMILES and list of labels\n",
    "data_list = create_pytorch_geometric_graph_data_list_from_smiles_and_labels(bbbp.smiles, bbbp.p_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "103a66eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[20, 79], edge_index=[2, 40], edge_attr=[40, 10], y=[1])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b35d0c",
   "metadata": {},
   "source": [
    "#### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b41572a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset:  0.8\n",
      "valid dataset:  0.09974683544303797\n",
      "test dataset:   0.10025316455696202\n"
     ]
    }
   ],
   "source": [
    "# split data into training, validation, and test sets\n",
    "\n",
    "labels = [int(data.y) for data in data_list] # array-like for stratification\n",
    "train_ds, rest_list = train_test_split(data_list, train_size=0.8, stratify=labels)\n",
    "\n",
    "labels = [int(data.y) for data in rest_list] # array-like for stratification\n",
    "valid_ds, test_ds = train_test_split(rest_list, test_size=0.5, stratify=labels)\n",
    "\n",
    "# print set ratios\n",
    "\n",
    "total_len = len(bbbp)\n",
    "\n",
    "print(\"train dataset:\".ljust(15, \" \"), len(train_ds)/total_len) # 0.80\n",
    "print(\"valid dataset:\".ljust(15, \" \"), len(valid_ds)/total_len) # 0.10\n",
    "print(\"test dataset:\".ljust(15, \" \"), len(test_ds)/total_len) #0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9c6d4cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create torch_geometric.loader.DataLoader objects\n",
    "\n",
    "batch_size = 2**6 # 64\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34059c7",
   "metadata": {},
   "source": [
    "# Implementing a GNN using the PyTorch Geometric library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8f51df70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, num_node_features, num_edge_features):\n",
    "        super().__init__()\n",
    "        conv1_net = nn.Sequential(\n",
    "            nn.Linear(num_edge_features, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_node_features*32)\n",
    "        )\n",
    "        \n",
    "        conv2_net = nn.Sequential(\n",
    "            nn.Linear(num_edge_features, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32*16)\n",
    "        )\n",
    "        \n",
    "        self.conv1 = NNConv(num_node_features, 32, conv1_net)\n",
    "        self.conv2 = NNConv(32,16, conv2_net)\n",
    "        self.fc_1 = nn.Linear(16, 32)\n",
    "        self.out = nn.Linear(32, 1)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        batch, x, edge_index, edge_attr = (data.batch, data.x, data.edge_index, data.edge_attr)\n",
    "        \n",
    "        # First graph conv layer\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        \n",
    "        # Second graph conv layer\n",
    "        x = F.relu(self.conv2(x, edge_index, edge_attr))\n",
    "        \n",
    "        x = global_add_pool(x,batch)\n",
    "        x = F.relu(self.fc_1(x))\n",
    "        output = self.out(x)\n",
    "        \n",
    "        output = torch.sigmoid(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "00288983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): NNConv(79, 32, aggr=add, nn=Sequential(\n",
       "    (0): Linear(in_features=10, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=2528, bias=True)\n",
       "  ))\n",
       "  (conv2): NNConv(32, 16, aggr=add, nn=Sequential(\n",
       "    (0): Linear(in_features=10, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=512, bias=True)\n",
       "  ))\n",
       "  (fc_1): Linear(in_features=16, out_features=32, bias=True)\n",
       "  (out): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the network\n",
    "\n",
    "num_node_features = data_list[0].num_node_features\n",
    "num_edge_features = data_list[0].num_edge_features\n",
    "\n",
    "model = Network(num_node_features, num_edge_features)\n",
    "\n",
    "# initialize optimizer\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "902f9d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, train_loader, val_loader, num_epochs):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    best_f1 = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for data in train_loader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, data.y.view(-1, 1).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * data.num_graphs\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        y_true = []\n",
    "        y_prob = []\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                data = data.to(device)\n",
    "                output = model(data)\n",
    "                loss = loss_fn(output, data.y.view(-1, 1).float())\n",
    "                val_loss += loss.item() * data.num_graphs\n",
    "                y_true.append(data.y.detach().cpu().numpy())\n",
    "                y_prob.append(output.detach().cpu().numpy())\n",
    "            val_loss /= len(val_loader.dataset)\n",
    "\n",
    "        y_true = np.concatenate(y_true)\n",
    "        y_prob = np.concatenate(y_prob)\n",
    "        y_pred = np.where(y_prob >= 0.5, 1, 0)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "        print(f\"Epoch {epoch+1:0>2}, train loss: {train_loss:.4f}, valid loss: {val_loss:.4f}, valid F1-score: {f1:.4f}\")\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "\n",
    "    print(f\"Best validation F1-score: {best_f1:.4f}\")\n",
    "    model.load_state_dict(torch.load('best_model.pt'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d5c4df8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01, train loss: 0.8513, valid loss: 0.5069, valid F1-score: 0.8776\n",
      "Epoch 02, train loss: 0.4884, valid loss: 0.4679, valid F1-score: 0.8730\n",
      "Epoch 03, train loss: 0.4415, valid loss: 0.4777, valid F1-score: 0.8827\n",
      "Epoch 04, train loss: 0.4180, valid loss: 0.4318, valid F1-score: 0.8952\n",
      "Epoch 05, train loss: 0.3993, valid loss: 0.4604, valid F1-score: 0.8609\n",
      "Epoch 06, train loss: 0.3953, valid loss: 0.4658, valid F1-score: 0.8462\n",
      "Epoch 07, train loss: 0.3933, valid loss: 0.4043, valid F1-score: 0.8939\n",
      "Epoch 08, train loss: 0.3864, valid loss: 0.4226, valid F1-score: 0.9012\n",
      "Epoch 09, train loss: 0.3801, valid loss: 0.4133, valid F1-score: 0.8859\n",
      "Epoch 10, train loss: 0.3640, valid loss: 0.4096, valid F1-score: 0.9051\n",
      "Epoch 11, train loss: 0.3652, valid loss: 0.3762, valid F1-score: 0.9079\n",
      "Epoch 12, train loss: 0.3300, valid loss: 0.4040, valid F1-score: 0.9102\n",
      "Epoch 13, train loss: 0.3325, valid loss: 0.3826, valid F1-score: 0.9079\n",
      "Epoch 14, train loss: 0.3313, valid loss: 0.4017, valid F1-score: 0.8925\n",
      "Epoch 15, train loss: 0.3208, valid loss: 0.3735, valid F1-score: 0.9132\n",
      "Epoch 16, train loss: 0.3189, valid loss: 0.3781, valid F1-score: 0.9091\n",
      "Epoch 17, train loss: 0.3168, valid loss: 0.4032, valid F1-score: 0.9202\n",
      "Epoch 18, train loss: 0.3083, valid loss: 0.3728, valid F1-score: 0.9097\n",
      "Epoch 19, train loss: 0.3077, valid loss: 0.3610, valid F1-score: 0.9007\n",
      "Epoch 20, train loss: 0.3312, valid loss: 0.3732, valid F1-score: 0.9164\n",
      "Best validation F1-score: 0.9202\n"
     ]
    }
   ],
   "source": [
    "trained_model = train(model, optimizer, loss_fn, train_dl, valid_dl, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "886b7556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, device):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize the lists for the true labels and predicted probabilities\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Iterate over the validation data\n",
    "        for data in loader:\n",
    "            # Move the data to the specified device\n",
    "            data = data.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(data)\n",
    "            \n",
    "            # Convert the predicted probabilities to binary predictions\n",
    "            y_pred_batch = (output > 0.5).int().cpu().numpy()\n",
    "            \n",
    "            # Append the true labels and predicted binary labels to the lists\n",
    "            y_true.append(data.y.cpu().numpy())\n",
    "            y_pred.append(y_pred_batch)\n",
    "    \n",
    "    # Concatenate the lists to obtain the true labels and predicted binary labels for the entire dataset\n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    \n",
    "    # Calculate the relevant performance metrics\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    \n",
    "    return f1, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a6d33a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 on test set: 0.9221183800623054 \n",
      "ROC-AUC on test set: 0.7537499999999999\n"
     ]
    }
   ],
   "source": [
    "test_f1, test_roc_auc = evaluate(model, test_dl, 'cpu')\n",
    "print(\"F1 on test set:\", test_f1, \n",
    "      \"\\nROC-AUC on test set:\", test_roc_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlms2023]",
   "language": "python",
   "name": "conda-env-mlms2023-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
